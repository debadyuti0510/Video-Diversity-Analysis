{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3da67bc2-8f36-464b-80c9-d1b178cce952",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "import datasets\n",
    "import joblib\n",
    "from transformers import CLIPProcessor, CLIPModel, CLIPVisionModel\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "import pandas as pd\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "from matplotlib import pyplot as plt\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e31c243b-cdad-4a9e-887d-b119b2ed2858",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1b94b6cf8b0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f46de10a-abdb-446f-8571-3cd7f14673d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "583c124a-b64f-41d6-9c9c-17a93657b86f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "210bb6f1-047e-4d91-a316-56f7a5559a29",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load model and pre-processor\n",
    "model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "model.to(device)\n",
    "vision_model = CLIPVisionModel.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "vision_model.to(device)\n",
    "processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ec9cc1d7-11d5-473a-b6a0-972b6a00bb04",
   "metadata": {},
   "outputs": [],
   "source": [
    "age_texts = [f\"A person in the {c} age group\" for c in [\"0-2\", \"3-9\", \"10-19\", \"20-29\", \"30-39\", \"40-49\", \"50-59\", \"60-69\", \"more than 70\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5b906ed3-a3e1-4223-af10-0c5c1671028e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_embedding_and_zs(sample):\n",
    "    # import pdb; pdb.set_trace()\n",
    "\n",
    "    # Age prediction\n",
    "    age_texts = [f\"A person in the {c} age group\" for c in [\"0-2\", \"3-9\", \"10-19\", \"20-29\", \"30-39\", \"40-49\", \"50-59\", \"60-69\", \"more than 70\"]]\n",
    "    inputs = processor(text=age_texts, images=sample[\"image\"], return_tensors=\"pt\", padding=True).to(device)\n",
    "    outputs = model(**inputs)\n",
    "    logits_per_image = outputs.logits_per_image # this is the image-text similarity score\n",
    "    age_pred = logits_per_image.argmax(dim=1) # we can take the argmax\n",
    "    \n",
    "    sample[\"zs_age_clip\"] = [int(gp) for gp in age_pred]\n",
    "    # Store embeddings\n",
    "    sample[\"embeddings\"] = outputs.image_embeds\n",
    "    \n",
    "    \n",
    "    return sample\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "428af532-1e7a-451c-bcdf-c053c8204b11",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load training data\n",
    "train_ds = datasets.load_dataset('HuggingFaceM4/FairFace', '1.25', split='train', verification_mode=\"no_checks\")\n",
    "# train_ds = train_ds.shuffle(seed=42).select([i for i in range(1_000)]) # Take only first 20_000 images\n",
    "train_ds = train_ds.shuffle(seed=42)\n",
    "# train_ds = train_ds.map(get_embedding_and_zs, batched = True, batch_size=16)\n",
    "# train_ds = train_ds.map(get_deepface_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8d2cba02-aea0-4383-8d07-c57d3a3f5227",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Debadyuti\\.conda\\envs\\dissertation-env\\lib\\site-packages\\transformers\\models\\clip\\modeling_clip.py:480: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:555.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n"
     ]
    }
   ],
   "source": [
    "train_ds[0][\"image\"]\n",
    "inputs = processor(images=train_ds[0][\"image\"], return_tensors=\"pt\", padding=True).to(device)\n",
    "outputs = vision_model(**inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "709e0495",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 768])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.pooler_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "907d1cfc-2eae-4861-960d-026cdaa66636",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds[5][\"age\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "af13af03-5922-4548-ad1a-718c64408469",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load validation data and test on this\n",
    "test_valid_ds = datasets.load_dataset('HuggingFaceM4/FairFace', '1.25', split=\"validation\", verification_mode=\"no_checks\")\n",
    "valid_ds = test_valid_ds.shuffle(seed=42).select([i for i in range(6_000)]) # Take only first 6_000 images'\n",
    "test_ds = test_valid_ds.shuffle(seed=42).select([i for i in range(6_000, len(test_valid_ds))])\n",
    "# valid_ds = valid_ds.shuffle(seed=42) \n",
    "valid_ds = valid_ds.map(get_embedding_and_zs, batched = True, batch_size=16)\n",
    "test_ds = test_ds.map(get_embedding_and_zs, batched = True, batch_size=16)\n",
    "# valid_ds = valid_ds.map(get_deepface_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "63beb359",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(test_valid_ds) == len(test_ds) + len(valid_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "de4fb225-8374-4ce6-aa19-47284564deb0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Load test data as second 50% of val split\n",
    "# test_ds = datasets.load_dataset('HuggingFaceM4/FairFace', '1.25', split=\"validation[50%:]\", verification_mode=\"no_checks\")\n",
    "# test_ds = test_ds.shuffle(seed=42).select([i for i in range(6_000)]) # Take only first 6_000 images\n",
    "# test_ds = test_ds.map(get_embedding_and_zs, batched = True, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "969ea673-eff9-45e3-8f87-b72732ab9bb8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['image', 'age', 'gender', 'race', 'service_test', 'zs_age_clip', 'embeddings'],\n",
       "    num_rows: 86744\n",
       "})"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1632b923-bb87-4ecf-8ddd-f77e783003ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "# tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "0463d3e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(train_ds[\"embeddings\"])\n",
    "y_train_age = np.array(train_ds[\"age\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "09d5b1ea-414c-4c1d-8e25-214e22274788",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val = np.array(valid_ds[\"embeddings\"])\n",
    "y_val_age = np.array(valid_ds[\"age\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "71fd1fdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(512,)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a118060b",
   "metadata": {},
   "source": [
    "# Tree-based exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "9f32bd52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the data as a DMatrix\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train_age)\n",
    "dval = xgb.DMatrix(X_val, label=y_val_age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b281791",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "param = {'max_depth': 8, 'eta': 0.3, 'objective': 'multi:softmax'}\n",
    "param['nthread'] = 4\n",
    "param['eval_metric'] = 'auc'\n",
    "param[\"num_class\"] = 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "34dfa281",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dtrain' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m evallist \u001b[38;5;241m=\u001b[39m [(\u001b[43mdtrain\u001b[49m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m), (dval, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124meval\u001b[39m\u001b[38;5;124m'\u001b[39m)]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'dtrain' is not defined"
     ]
    }
   ],
   "source": [
    "evallist = [(dtrain, 'train'), (dval, 'eval')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bfe9b8ca",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'xgb' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m num_round \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m75\u001b[39m\n\u001b[1;32m----> 2\u001b[0m bst \u001b[38;5;241m=\u001b[39m \u001b[43mxgb\u001b[49m\u001b[38;5;241m.\u001b[39mtrain(param, dtrain, num_round, evallist)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'xgb' is not defined"
     ]
    }
   ],
   "source": [
    "num_round = 75\n",
    "bst = xgb.train(param, dtrain, num_round, evallist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0209f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(X_train)\n",
    "y_preds = bst.predict(dtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5872e51b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGB+CLIP accuracy for 0-2(class-0): 99.83%\n",
      "XGB+CLIP accuracy for 3-9(class-1): 99.96%\n",
      "XGB+CLIP accuracy for 10-19(class-2): 99.27%\n",
      "XGB+CLIP accuracy for 20-29(class-3): 99.14%\n",
      "XGB+CLIP accuracy for 30-39(class-4): 97.67%\n",
      "XGB+CLIP accuracy for 40-49(class-5): 98.89%\n",
      "XGB+CLIP accuracy for 50-59(class-6): 99.87%\n",
      "XGB+CLIP accuracy for 60-69(class-7): 100.00%\n",
      "XGB+CLIP accuracy for more than 70(class-8): 99.76%\n"
     ]
    }
   ],
   "source": [
    "cwise_acc = []\n",
    "for idx, age in enumerate([\"0-2\", \"3-9\", \"10-19\", \"20-29\", \"30-39\", \"40-49\", \"50-59\", \"60-69\", \"more than 70\"]):\n",
    "    age_mask = np.array(y_train_age) == idx\n",
    "    y_true = np.array(y_train_age)[age_mask]\n",
    "    y_rel_preds = np.array(y_preds)[age_mask]\n",
    "    age_acc = np.sum(y_true == y_rel_preds) / len(y_true) * 100\n",
    "    cwise_acc.append(age_acc)\n",
    "    print(f\"XGB+CLIP accuracy for {age}(class-{idx}): {age_acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cfc00f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dval = xgb.DMatrix(X_val)\n",
    "y_preds = bst.predict(dval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f01f1bf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGB + CLIP accuracy for 0-2(class-0): 67.31%\n",
      "XGB + CLIP accuracy for 3-9(class-1): 82.83%\n",
      "XGB + CLIP accuracy for 10-19(class-2): 42.09%\n",
      "XGB + CLIP accuracy for 20-29(class-3): 73.85%\n",
      "XGB + CLIP accuracy for 30-39(class-4): 49.01%\n",
      "XGB + CLIP accuracy for 40-49(class-5): 45.48%\n",
      "XGB + CLIP accuracy for 50-59(class-6): 38.27%\n",
      "XGB + CLIP accuracy for 60-69(class-7): 38.64%\n",
      "XGB + CLIP accuracy for more than 70(class-8): 26.98%\n"
     ]
    }
   ],
   "source": [
    "val_cwise_acc_xgb = []\n",
    "for idx, age in enumerate([\"0-2\", \"3-9\", \"10-19\", \"20-29\", \"30-39\", \"40-49\", \"50-59\", \"60-69\", \"more than 70\"]):\n",
    "    age_mask = np.array(y_val_age) == idx\n",
    "    y_true = np.array(y_val_age)[age_mask]\n",
    "    y_rel_preds = np.array(y_preds)[age_mask]\n",
    "    age_acc = np.sum(y_true == y_rel_preds) / len(y_true) * 100\n",
    "    val_cwise_acc_xgb.append(age_acc)\n",
    "    print(f\"XGB + CLIP accuracy for {age}(class-{idx}): {age_acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc4a548a",
   "metadata": {},
   "source": [
    "# NN + CLIP Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "5edbb4b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define TensorDataset and DataLoader\n",
    "train_ds_torch = TensorDataset(torch.tensor(X_train, dtype=torch.float), torch.tensor(y_train_age, dtype=torch.long))\n",
    "train_dataloader = DataLoader(train_ds_torch, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "e6df289c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define TensorDataset and DataLoader\n",
    "val_ds_torch = TensorDataset(torch.tensor(X_val, dtype=torch.float), torch.tensor(y_val_age, dtype=torch.long))\n",
    "val_dataloader = DataLoader(val_ds_torch, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "f7d7f92a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Linear(512, 256)\n",
    "        self.layer2 = nn.Linear(256, 64)\n",
    "        self.layer3 = nn.Linear(64, 9)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.layer2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.layer3(x)\n",
    "        return x\n",
    "    \n",
    "network = SimpleNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "a3fd54da",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(network.parameters(), lr=0.001, betas=(0.9, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "313ed839",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d84800b977244e748be9f705b5eada0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed Training!\n"
     ]
    }
   ],
   "source": [
    "# Training for 40 epochs\n",
    "loss_collection = []\n",
    "for epoch in tqdm(range(40)):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_dataloader):\n",
    "        inputs, labels = data\n",
    "\n",
    "        # Zero out the gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward pass\n",
    "        outputs = network(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        # backward pass\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "\n",
    "        # print loss\n",
    "        running_loss += loss.item()\n",
    "    loss_collection.append(running_loss/len(train_dataloader))\n",
    "    # print(f\"Loss after epoch {epoch + 1} - {running_loss / len(train_dataloader) : .3f} \")\n",
    "\n",
    "print(\"Completed Training!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "f578dfbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x15746bbfb20>]"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the graph brother\n",
    "plt.plot(loss_collection)\n",
    "\n",
    "# torch.argmax(torch.tensor([[0,1,2], [0,3,2], [1,5,2], [0,-1,2], [0,1,1]]), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "e726626f",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = []\n",
    "actual = []\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in train_dataloader:\n",
    "        inputs, labels = data\n",
    "        actual += labels.tolist()\n",
    "        outputs = network(inputs)\n",
    "        pred = torch.argmax(outputs, dim=1)\n",
    "        total += len(inputs)\n",
    "        preds += pred.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "8b8f80bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN + CLIP accuracy for 0-2(class-0): 96.15%\n",
      "NN + CLIP accuracy for 3-9(class-1): 97.03%\n",
      "NN + CLIP accuracy for 10-19(class-2): 92.71%\n",
      "NN + CLIP accuracy for 20-29(class-3): 91.83%\n",
      "NN + CLIP accuracy for 30-39(class-4): 89.53%\n",
      "NN + CLIP accuracy for 40-49(class-5): 93.20%\n",
      "NN + CLIP accuracy for 50-59(class-6): 79.77%\n",
      "NN + CLIP accuracy for 60-69(class-7): 91.15%\n",
      "NN + CLIP accuracy for more than 70(class-8): 97.86%\n"
     ]
    }
   ],
   "source": [
    "cwise_acc = []\n",
    "for idx, age in enumerate([\"0-2\", \"3-9\", \"10-19\", \"20-29\", \"30-39\", \"40-49\", \"50-59\", \"60-69\", \"more than 70\"]):\n",
    "    age_mask = np.array(actual) == idx\n",
    "    y_true = np.array(actual)[age_mask]\n",
    "    y_rel_preds = np.array(preds)[age_mask]\n",
    "    age_acc = np.sum(y_true == y_rel_preds) / len(y_true) * 100\n",
    "    cwise_acc.append(age_acc)\n",
    "    print(f\"NN + CLIP accuracy for {age}(class-{idx}): {age_acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "e539bb92",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = []\n",
    "actual = []\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in val_dataloader:\n",
    "        inputs, labels = data\n",
    "        actual += labels.tolist()\n",
    "        outputs = network(inputs)\n",
    "        pred = torch.argmax(outputs, dim=1)\n",
    "        total += len(inputs)\n",
    "        preds += pred.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "6a8fdfe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy for Age: 52.1910%\n"
     ]
    }
   ],
   "source": [
    "val_acc = np.sum(np.array(preds) == np.array(actual)) / total\n",
    "print(f\"Validation accuracy for Age: {val_acc*100:.4f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "7b4e88ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN + CLIP accuracy for 0-2(class-0): 74.37%\n",
      "NN + CLIP accuracy for 3-9(class-1): 75.88%\n",
      "NN + CLIP accuracy for 10-19(class-2): 43.78%\n",
      "NN + CLIP accuracy for 20-29(class-3): 57.82%\n",
      "NN + CLIP accuracy for 30-39(class-4): 45.36%\n",
      "NN + CLIP accuracy for 40-49(class-5): 45.82%\n",
      "NN + CLIP accuracy for 50-59(class-6): 30.15%\n",
      "NN + CLIP accuracy for 60-69(class-7): 44.55%\n",
      "NN + CLIP accuracy for more than 70(class-8): 46.61%\n"
     ]
    }
   ],
   "source": [
    "val_cwise_acc_nn = []\n",
    "for idx, age in enumerate([\"0-2\", \"3-9\", \"10-19\", \"20-29\", \"30-39\", \"40-49\", \"50-59\", \"60-69\", \"more than 70\"]):\n",
    "    age_mask = np.array(actual) == idx\n",
    "    y_true = np.array(actual)[age_mask]\n",
    "    y_rel_preds = np.array(preds)[age_mask]\n",
    "    age_acc = np.sum(y_true == y_rel_preds) / len(y_true) * 100\n",
    "    val_cwise_acc_nn.append(age_acc)\n",
    "    print(f\"NN + CLIP accuracy for {age}(class-{idx}): {age_acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85a7e09d",
   "metadata": {},
   "source": [
    "# Measuring LR and ZS performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e5bbf9-3690-4c2e-9fcf-6bfe0d870b32",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-4 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-4 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-4 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-4 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-4 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-4 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-4 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-4 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-4 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=400, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;LogisticRegression<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression(max_iter=400, random_state=42)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(max_iter=400, random_state=42)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_clf_age = LogisticRegression(random_state=42, max_iter=400)\n",
    "lr_clf_age.fit(X_train, y_train_age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6ccc7194-0e6d-47b9-a72d-c8772db981b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy for Age: 61.4636%\n",
      "Validation accuracy for Age: 61.1010%\n"
     ]
    }
   ],
   "source": [
    "train_acc = lr_clf_age.score(X_train, y_train_age)\n",
    "val_acc = lr_clf_age.score(X_val, y_val_age)\n",
    "print(f\"Training accuracy for Age: {train_acc*100:.4f}%\")\n",
    "print(f\"Validation accuracy for Age: {val_acc*100:.4f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f7ed6477-7146-4344-be75-4aad2c4a7cff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution of Age Categories in FairFace\n",
      "0-2 -  2.07%\n",
      "3-9 -  12.00%\n",
      "10-19 -  10.49%\n",
      "20-29 -  29.51%\n",
      "30-39 -  22.19%\n",
      "40-49 -  12.39%\n",
      "50-59 -  7.18%\n",
      "60-69 -  3.20%\n",
      "more than 70 -  0.97%\n"
     ]
    }
   ],
   "source": [
    "# Distribution of age categories\n",
    "print(\"Distribution of Age Categories in FairFace\")\n",
    "distribution_of_ages  = []\n",
    "cat, counts = np.unique(y_train_age, return_counts=True)\n",
    "total_counts = np.sum(counts)\n",
    "pcts = []\n",
    "for idx, c in enumerate([\"0-2\", \"3-9\", \"10-19\", \"20-29\", \"30-39\", \"40-49\", \"50-59\", \"60-69\", \"more than 70\"]):\n",
    "    pct = counts[idx]/total_counts*100\n",
    "    print(f\"{c} - {pct : .2f}%\")\n",
    "    pcts.append(pct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "3a632833-f72d-416e-a4c6-ce000e5166f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_preds = lr_clf_gender.predict(X_train)\n",
    "# from sklearn.metrics import precision_recall_fscore_support\n",
    "# precision_recall_fscore_support(y_train_gender, y_preds, average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "7d7528c1-3b6c-429f-84c7-017e3be3469d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_acc = lr_clf_race.score(X_train, y_train_race)\n",
    "# val_acc = lr_clf_race.score(X_val, y_val_race)\n",
    "# print(f\"Training accuracy for race: {train_acc*100:.4f}%\")\n",
    "# print(f\"Validation accuracy for race: {val_acc*100:.4f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e4caeb42-725f-4334-8f16-b22395b61a46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set metrics - Age (LR + CLIP) \n",
      "========================================\n",
      "Accuracy: 0.6146 Precision: 0.6096, Recall: 0.6146, F-Score(Weighted): 0.6083, F-Score(Micro): 0.6146, F-Score(Macro): 0.5894\n"
     ]
    }
   ],
   "source": [
    "y_preds = lr_clf_age.predict(X_train)\n",
    "precision, recall, f_score_weighted, _ = precision_recall_fscore_support(y_train_age, y_preds, average='weighted')\n",
    "_, _, f_score_macro, _ = precision_recall_fscore_support(y_train_age, y_preds, average='macro')\n",
    "_, _, f_score_micro, _ = precision_recall_fscore_support(y_train_age, y_preds, average='micro')\n",
    "train_acc = lr_clf_age.score(X_train, y_train_age)\n",
    "print(f\"Training set metrics - Age (LR + CLIP) \\n\" + \"=\"*40)\n",
    "print(f\"Accuracy: {train_acc:.4f} Precision: {precision:.4f}, Recall: {recall:.4f}, F-Score(Weighted): {f_score_weighted:.4f}, F-Score(Micro): {f_score_micro:.4f}, F-Score(Macro): {f_score_macro:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "484c03a9-6d9d-4bda-ab77-7a0df3e6c17b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR+CLIP accuracy for 0-2(class-0): 68.69%\n",
      "LR+CLIP accuracy for 3-9(class-1): 86.75%\n",
      "LR+CLIP accuracy for 10-19(class-2): 44.22%\n",
      "LR+CLIP accuracy for 20-29(class-3): 75.60%\n",
      "LR+CLIP accuracy for 30-39(class-4): 51.50%\n",
      "LR+CLIP accuracy for 40-49(class-5): 46.84%\n",
      "LR+CLIP accuracy for 50-59(class-6): 50.87%\n",
      "LR+CLIP accuracy for 60-69(class-7): 43.94%\n",
      "LR+CLIP accuracy for more than 70(class-8): 41.09%\n"
     ]
    }
   ],
   "source": [
    "cwise_acc = []\n",
    "for idx, age in enumerate([\"0-2\", \"3-9\", \"10-19\", \"20-29\", \"30-39\", \"40-49\", \"50-59\", \"60-69\", \"more than 70\"]):\n",
    "    age_mask = np.array(y_train_age) == idx\n",
    "    y_true = np.array(y_train_age)[age_mask]\n",
    "    y_rel_preds = np.array(y_preds)[age_mask]\n",
    "    age_acc = np.sum(y_true == y_rel_preds) / len(y_true) * 100\n",
    "    cwise_acc.append(age_acc)\n",
    "    print(f\"LR+CLIP accuracy for {age}(class-{idx}): {age_acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "8e883c9e-2988-42d6-b9a1-655bdeb3bb48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation set metrics - Age (LR + CLIP)\n",
      "========================================\n",
      "Accuracy: 0.6110 Precision: 0.6053, Recall: 0.6110, F-Score(Weighted): 0.6045, F-Score(Micro): 0.6110, F-Score(Macro): 0.5740\n"
     ]
    }
   ],
   "source": [
    "y_preds = lr_clf_age.predict(X_val)\n",
    "precision, recall, f_score_weighted, _ = precision_recall_fscore_support(y_val_age, y_preds, average='weighted')\n",
    "_, _, f_score_macro, _ = precision_recall_fscore_support(y_val_age, y_preds, average='macro')\n",
    "_, _, f_score_micro, _ = precision_recall_fscore_support(y_val_age, y_preds, average='micro')\n",
    "val_acc = lr_clf_age.score(X_val, y_val_age)\n",
    "print(f\"Validation set metrics - Age (LR + CLIP)\\n\" + \"=\"*40)\n",
    "print(f\"Accuracy: {val_acc:.4f} Precision: {precision:.4f}, Recall: {recall:.4f}, F-Score(Weighted): {f_score_weighted:.4f}, F-Score(Micro): {f_score_micro:.4f}, F-Score(Macro): {f_score_macro:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "84ef64a0-36cf-4463-b226-bec537f1f6f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR+CLIP accuracy for 0-2(class-0): 71.36%\n",
      "LR+CLIP accuracy for 3-9(class-1): 86.36%\n",
      "LR+CLIP accuracy for 10-19(class-2): 44.03%\n",
      "LR+CLIP accuracy for 20-29(class-3): 75.12%\n",
      "LR+CLIP accuracy for 30-39(class-4): 51.03%\n",
      "LR+CLIP accuracy for 40-49(class-5): 46.56%\n",
      "LR+CLIP accuracy for 50-59(class-6): 46.48%\n",
      "LR+CLIP accuracy for 60-69(class-7): 48.91%\n",
      "LR+CLIP accuracy for more than 70(class-8): 29.66%\n"
     ]
    }
   ],
   "source": [
    "val_cwise_acc=[]\n",
    "for idx, age in enumerate([\"0-2\", \"3-9\", \"10-19\", \"20-29\", \"30-39\", \"40-49\", \"50-59\", \"60-69\", \"more than 70\"]):\n",
    "    age_mask = np.array(y_val_age) == idx\n",
    "    y_true = np.array(y_val_age)[age_mask]\n",
    "    y_rel_preds = np.array(y_preds)[age_mask]\n",
    "    age_acc = np.sum(y_true == y_rel_preds) / len(y_true) * 100\n",
    "    val_cwise_acc.append(age_acc)\n",
    "    print(f\"LR+CLIP accuracy for {age}(class-{idx}): {age_acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "c712aa4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation set metrics - Age (Zero-Shot CLIP)\n",
      "========================================\n",
      "Accuracy: 0.6110 Precision: 0.4782, Recall: 0.3984, F-Score(Weighted): 0.4110, F-Score(Micro): 0.3984, F-Score(Macro): 0.3714\n"
     ]
    }
   ],
   "source": [
    "y_preds = valid_ds[\"zs_age_clip\"]\n",
    "precision, recall, f_score_weighted, _ = precision_recall_fscore_support(y_val_age, y_preds, average='weighted')\n",
    "_, _, f_score_macro, _ = precision_recall_fscore_support(y_val_age, y_preds, average='macro')\n",
    "_, _, f_score_micro, _ = precision_recall_fscore_support(y_val_age, y_preds, average='micro')\n",
    "val_acc = lr_clf_age.score(X_val, y_val_age)\n",
    "print(f\"Validation set metrics - Age (Zero-Shot CLIP)\\n\" + \"=\"*40)\n",
    "print(f\"Accuracy: {val_acc:.4f} Precision: {precision:.4f}, Recall: {recall:.4f}, F-Score(Weighted): {f_score_weighted:.4f}, F-Score(Micro): {f_score_micro:.4f}, F-Score(Macro): {f_score_macro:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "b052962d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zero-Shot CLIP accuracy for 0-2(class-0): 76.38%\n",
      "Zero-Shot CLIP accuracy for 3-9(class-1): 57.08%\n",
      "Zero-Shot CLIP accuracy for 10-19(class-2): 58.00%\n",
      "Zero-Shot CLIP accuracy for 20-29(class-3): 27.70%\n",
      "Zero-Shot CLIP accuracy for 30-39(class-4): 50.56%\n",
      "Zero-Shot CLIP accuracy for 40-49(class-5): 23.95%\n",
      "Zero-Shot CLIP accuracy for 50-59(class-6): 23.24%\n",
      "Zero-Shot CLIP accuracy for 60-69(class-7): 17.45%\n",
      "Zero-Shot CLIP accuracy for more than 70(class-8): 81.36%\n"
     ]
    }
   ],
   "source": [
    "val_cwise_zs_acc=[]\n",
    "for idx, age in enumerate([\"0-2\", \"3-9\", \"10-19\", \"20-29\", \"30-39\", \"40-49\", \"50-59\", \"60-69\", \"more than 70\"]):\n",
    "    age_mask = np.array(y_val_age) == idx\n",
    "    y_true = np.array(y_val_age)[age_mask]\n",
    "    y_rel_preds = np.array(y_preds)[age_mask]\n",
    "    age_acc = np.sum(y_true == y_rel_preds) / len(y_true) * 100\n",
    "    val_cwise_zs_acc.append(age_acc)\n",
    "    print(f\"Zero-Shot CLIP accuracy for {age}(class-{idx}): {age_acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "9dd4a491",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age Group</th>\n",
       "      <th>Distribution</th>\n",
       "      <th>Training Accuracy</th>\n",
       "      <th>Validation Accuracy</th>\n",
       "      <th>Validation ZS Accuracy</th>\n",
       "      <th>Percent improvement</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0-2</td>\n",
       "      <td>2.065849</td>\n",
       "      <td>68.694196</td>\n",
       "      <td>71.356784</td>\n",
       "      <td>76.381910</td>\n",
       "      <td>-5.025126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3-9</td>\n",
       "      <td>11.998524</td>\n",
       "      <td>86.750576</td>\n",
       "      <td>86.356932</td>\n",
       "      <td>57.079646</td>\n",
       "      <td>29.277286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10-19</td>\n",
       "      <td>10.494098</td>\n",
       "      <td>44.216192</td>\n",
       "      <td>44.030483</td>\n",
       "      <td>58.001693</td>\n",
       "      <td>-13.971211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20-29</td>\n",
       "      <td>29.509822</td>\n",
       "      <td>75.595750</td>\n",
       "      <td>75.121212</td>\n",
       "      <td>27.696970</td>\n",
       "      <td>47.424242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30-39</td>\n",
       "      <td>22.191737</td>\n",
       "      <td>51.496104</td>\n",
       "      <td>51.030043</td>\n",
       "      <td>50.557940</td>\n",
       "      <td>0.472103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>40-49</td>\n",
       "      <td>12.385871</td>\n",
       "      <td>46.835443</td>\n",
       "      <td>46.563193</td>\n",
       "      <td>23.946785</td>\n",
       "      <td>22.616408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>50-59</td>\n",
       "      <td>7.179747</td>\n",
       "      <td>50.867052</td>\n",
       "      <td>46.482412</td>\n",
       "      <td>23.241206</td>\n",
       "      <td>23.241206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>60-69</td>\n",
       "      <td>3.203680</td>\n",
       "      <td>43.936668</td>\n",
       "      <td>48.909657</td>\n",
       "      <td>17.445483</td>\n",
       "      <td>31.464174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>more than 70</td>\n",
       "      <td>0.970672</td>\n",
       "      <td>41.092637</td>\n",
       "      <td>29.661017</td>\n",
       "      <td>81.355932</td>\n",
       "      <td>-51.694915</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Age Group  Distribution  Training Accuracy  Validation Accuracy  \\\n",
       "0           0-2      2.065849          68.694196            71.356784   \n",
       "1           3-9     11.998524          86.750576            86.356932   \n",
       "2         10-19     10.494098          44.216192            44.030483   \n",
       "3         20-29     29.509822          75.595750            75.121212   \n",
       "4         30-39     22.191737          51.496104            51.030043   \n",
       "5         40-49     12.385871          46.835443            46.563193   \n",
       "6         50-59      7.179747          50.867052            46.482412   \n",
       "7         60-69      3.203680          43.936668            48.909657   \n",
       "8  more than 70      0.970672          41.092637            29.661017   \n",
       "\n",
       "   Validation ZS Accuracy  Percent improvement  \n",
       "0               76.381910            -5.025126  \n",
       "1               57.079646            29.277286  \n",
       "2               58.001693           -13.971211  \n",
       "3               27.696970            47.424242  \n",
       "4               50.557940             0.472103  \n",
       "5               23.946785            22.616408  \n",
       "6               23.241206            23.241206  \n",
       "7               17.445483            31.464174  \n",
       "8               81.355932           -51.694915  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "age_cats = [\"0-2\", \"3-9\", \"10-19\", \"20-29\", \"30-39\", \"40-49\", \"50-59\", \"60-69\", \"more than 70\"]\n",
    "results_df = pd.DataFrame({\n",
    "    \"Age Group\": age_cats, \n",
    "    \"Distribution\": pcts, \n",
    "    \"Training Accuracy\": cwise_acc, \n",
    "    \"Validation Accuracy\": val_cwise_acc, \n",
    "    \"Validation ZS Accuracy\": val_cwise_zs_acc\n",
    "    } )\n",
    "results_df[\"Percent improvement\"] = results_df[\"Validation Accuracy\"] - results_df[\"Validation ZS Accuracy\"] \n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3b824bbb-3e0b-47fb-93b6-24d366fd6477",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved successfully!\n",
      "Model loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# Save Emotion model\n",
    "joblib.dump(lr_clf_age, '../models/lr_clf_age.joblib')\n",
    "print(\"Model saved successfully!\")\n",
    "# To load the model from the file later\n",
    "clf_age_loaded = joblib.load('../models/lr_clf_age.joblib')\n",
    "print(\"Model loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be59bea-354a-43c6-92e7-4363831e7fce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dissertation-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
