{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ddf7918-396a-400a-98f2-5a986a460d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepface import DeepFace\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import os\n",
    "import shutil\n",
    "import json\n",
    "import uuid\n",
    "import traceback\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f564d26-99d1-496a-9a33-3b5eabd82fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "session_id = uuid.uuid4().hex[:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd1a113a-1e90-4720-a236-346ff3a5887e",
   "metadata": {},
   "source": [
    "# Clear out files and folders in data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fda0df9a-1451-416f-9b77-8471a3e27efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_experiment():\n",
    "    # Remove faces, embeddings, demography folders\n",
    "    if os.path.exists(\"data/frames\"):\n",
    "        shutil.rmtree(\"data/frames\")\n",
    "    os.mkdir(\"data/frames\")\n",
    "    \n",
    "    if os.path.exists(\"data/faces\"):\n",
    "        shutil.rmtree(\"data/faces\")\n",
    "    os.mkdir(\"data/faces\")\n",
    "    \n",
    "    if os.path.exists(\"data/embeddings\"):\n",
    "        shutil.rmtree(\"data/embeddings\")\n",
    "    os.mkdir(\"data/embeddings\")\n",
    "    \n",
    "    if os.path.exists(\"data/demography\"):\n",
    "        shutil.rmtree(\"data/demography\")\n",
    "    os.mkdir(\"data/demography\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e8d04dc-b2df-461d-97bc-a73d04760c15",
   "metadata": {},
   "source": [
    "# Capture the frames and display them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e61d2ae-abf7-4be2-ad05-7b51b74dc304",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(path):\n",
    "    cap = cv.VideoCapture(path)\n",
    "    # Open capture loop\n",
    "    ctr = 0\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()    \n",
    "        # ret is only true when frame is read properly\n",
    "        if not ret:\n",
    "            print(\"Cannot read frame.\")\n",
    "            break\n",
    "        if frame is None:\n",
    "            continue \n",
    "        # Display/Process every 15th frame\n",
    "        if ctr % 15 == 0:\n",
    "            # Add processing here\n",
    "            process_frame(frame, ctr)\n",
    "        if cv.waitKey(1) == ord('q'):\n",
    "            break\n",
    "        ctr += 1\n",
    "\n",
    "    cap.release()\n",
    "    cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b3fac40b-7edb-4960-b980-5441d18466ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "FACE_DETECTION_BACKEND = \"ssd\"\n",
    "FACE_EMBEDDINGS_BACKEND = \"Facenet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a0576186-4ee0-4d53-96f9-f0cf03b77963",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_frame(frame, frame_id):\n",
    "#     cv.imshow(\"face\", frame)\n",
    "#     print(f\"frame_id: {frame_id}\")\n",
    "#     return\n",
    "    # detect and highlight faces\n",
    "    try:\n",
    "\n",
    "        # Generate demography data\n",
    "        frame_data = DeepFace.analyze(img_path = frame, detector_backend = FACE_DETECTION_BACKEND)\n",
    "#         import ipdb; ipdb.set_trace()\n",
    "        # Generate embeddings using deepface\n",
    "        embedding_data = DeepFace.represent(img_path = frame, model_name = FACE_EMBEDDINGS_BACKEND,  detector_backend = FACE_DETECTION_BACKEND)\n",
    "        # For every face detected, store the image, face, embeddings, and dump the demography json\n",
    "        for idx, (f_data, e_data) in enumerate(zip(frame_data, embedding_data)):\n",
    "            file_name = f\"{session_id}_{frame_id}_{idx}\"\n",
    "            # Store the image\n",
    "            cv.imwrite(f\"data/frames/{file_name}.png\", frame)\n",
    "            # Extract the facial region and store/show the face\n",
    "            x,y,w,h = f_data[\"region\"][\"x\"], f_data[\"region\"][\"y\"], f_data[\"region\"][\"w\"], f_data[\"region\"][\"h\"]\n",
    "            # Make sure they represent the same face\n",
    "            assert(x == e_data[\"facial_area\"][\"x\"])\n",
    "            assert(y == e_data[\"facial_area\"][\"y\"])\n",
    "            assert(w == e_data[\"facial_area\"][\"w\"])\n",
    "            assert(h == e_data[\"facial_area\"][\"h\"])\n",
    "            x = max(int(x),0)\n",
    "            y = max(int(y),0)\n",
    "            w = max(int(w),0)\n",
    "            h = max(int(h),0)\n",
    "            face_region = frame[y:y+h, x:x+w,:]\n",
    "            cv.imwrite(f\"data/faces/{file_name}.png\", face_region)\n",
    "            cv.imshow(\"face\", face_region)\n",
    "            # Store the embeddings\n",
    "            np.save(f\"data/embeddings/{file_name}.npy\", e_data[\"embedding\"])\n",
    "            \n",
    "            # Dump the dict as a json\n",
    "            with open(f\"data/demography/{file_name}.json\", 'w') as f:\n",
    "                json.dump(f_data, f)\n",
    "            \n",
    "#         if len(frame_data) > 1:\n",
    "#             cv.imshow(\"face\", frame)\n",
    "#             cv2.setWindowProperty(\"face\", cv2.WND_PROP_TOPMOST, 1)\n",
    "        \n",
    "    except ValueError as ve:\n",
    "#         print(str(ve))\n",
    "        pass\n",
    "    except Exception as e:\n",
    "        print(str(e))\n",
    "        print(traceback.format_exc())\n",
    "        import ipdb; ipdb.set_trace()\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2162828a-3065-46e3-9f90-f15220cccf50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_embeddings(n_clusters=15):\n",
    "    # List all embeddings\n",
    "    embed_files = os.listdir(\"data/embeddings/\")\n",
    "    # Load all embeddings and their associated names(without extensions)\n",
    "    embeddings = { f_name.split(\".\")[0] : np.load(f\"data/embeddings/{f_name}\") for f_name in embed_files}\n",
    "\n",
    "    # Cluster the embeddings using sklearn, get the cluster centroids\n",
    "    embed_vals = np.array([val for val in embeddings.values()])\n",
    "#     import ipdb; ipdb.set_trace()\n",
    "    k_means_results = KMeans(n_clusters=n_clusters, random_state=42, n_init=5).fit(embed_vals)\n",
    "    # Assign the individual file prefix names to a centroid based on distance\n",
    "    cluster_assignments = {k:v for k,v in zip(embeddings.keys(), k_means_results.labels_)}\n",
    "    # Return file prefix - cluster number pairs\n",
    "    return cluster_assignments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f0d4ea5c-a2f0-4c29-bcde-0e85be10c1c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensemble_demography_assignment(centroids):\n",
    "    # For each clustered face, get the demography data and use the one race and gender that appears the most and assign that\n",
    "    # For the assigned race and gender, calculate the median confidence for those classes\n",
    "    # Return the cluster labels, and the race and gender with the median confidence\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e3320821-be33-4b0b-b014-c36fe6d856ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup_experiment()\n",
    "# run_experiment('data/movie/sample.mp4')\n",
    "assignments = cluster_embeddings(n_clusters=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "208ecb87-f997-4d32-9061-2891bd086ed6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "825f65c2-1986-49e5-a47c-4664fec8c26e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View all files with face #5\n",
    "import time\n",
    "relevant_files = [f\"data/faces/{k}.png\" for k,v in assignments.items() if v == 1]\n",
    "for f in relevant_files:\n",
    "    frame = cv.imread(f)\n",
    "    cv.imshow(\"Person-5\", frame)\n",
    "    # waits for user to press any key \n",
    "    # (this is necessary to avoid Python kernel form crashing) \n",
    "    cv.waitKey(0) \n",
    "\n",
    "    # closing all open windows \n",
    "    cv.destroyAllWindows() \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f1cf94-5150-41ce-b4a1-38897101581f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dissertation-env",
   "language": "python",
   "name": "dissertation-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
