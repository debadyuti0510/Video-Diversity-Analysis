{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ddf7918-396a-400a-98f2-5a986a460d6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Debadyuti\\anaconda3\\envs\\dissertation-env\\lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from deepface import DeepFace\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import os\n",
    "import shutil\n",
    "import json\n",
    "import uuid\n",
    "import traceback\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.metrics import silhouette_score\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "181cfa51-2c36-4f4f-8f8c-57ddd10cd612",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f564d26-99d1-496a-9a33-3b5eabd82fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "session_id = uuid.uuid4().hex[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3334443d-2d5d-4559-9281-a2a0fa2e25de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "FACE_DETECTION_BACKEND = \"ssd\"\n",
    "FACE_EMBEDDINGS_BACKEND = \"ArcFace\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e9c9914c-35f9-42b8-a496-e3de6dd0f40d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# session_id = f\"Buffy_{FACE_DETECTION_BACKEND}_{FACE_EMBEDDINGS_BACKEND}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd1a113a-1e90-4720-a236-346ff3a5887e",
   "metadata": {},
   "source": [
    "# Clear out files and folders in data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fda0df9a-1451-416f-9b77-8471a3e27efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_experiment():\n",
    "    # Remove faces, embeddings, demography folders\n",
    "    if os.path.exists(\"data/frames\"):\n",
    "        shutil.rmtree(\"data/frames\")\n",
    "    os.mkdir(\"data/frames\")\n",
    "    \n",
    "    if os.path.exists(\"data/faces\"):\n",
    "        shutil.rmtree(\"data/faces\")\n",
    "    os.mkdir(\"data/faces\")\n",
    "    \n",
    "    if os.path.exists(\"data/embeddings\"):\n",
    "        shutil.rmtree(\"data/embeddings\")\n",
    "    os.mkdir(\"data/embeddings\")\n",
    "    \n",
    "    if os.path.exists(\"data/demography\"):\n",
    "        shutil.rmtree(\"data/demography\")\n",
    "    os.mkdir(\"data/demography\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e8d04dc-b2df-461d-97bc-a73d04760c15",
   "metadata": {},
   "source": [
    "# Capture the frames and display them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3e61d2ae-abf7-4be2-ad05-7b51b74dc304",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(path):\n",
    "    cap = cv.VideoCapture(path)\n",
    "    # Open capture loop\n",
    "    ctr = 0\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()    \n",
    "        # ret is only true when frame is read properly\n",
    "        if not ret:\n",
    "            print(\"Cannot read frame.\")\n",
    "            break\n",
    "        if frame is None:\n",
    "            continue \n",
    "        # Display/Process every 15th frame\n",
    "        if ctr % 15 == 0:\n",
    "            # Add processing here\n",
    "            process_frame(frame, ctr)\n",
    "        if cv.waitKey(1) == ord('q'):\n",
    "            break\n",
    "        ctr += 1\n",
    "\n",
    "    cap.release()\n",
    "    cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3fac40b-7edb-4960-b980-5441d18466ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a0576186-4ee0-4d53-96f9-f0cf03b77963",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_frame(frame, frame_id):\n",
    "#     cv.imshow(\"face\", frame)\n",
    "#     print(f\"frame_id: {frame_id}\")\n",
    "#     return\n",
    "    # detect and highlight faces\n",
    "    try:\n",
    "\n",
    "        # Generate demography data\n",
    "        frame_data = DeepFace.analyze(img_path = frame, detector_backend = FACE_DETECTION_BACKEND)\n",
    "#         import ipdb; ipdb.set_trace()\n",
    "        # Generate embeddings using deepface\n",
    "        embedding_data = DeepFace.represent(img_path = frame, model_name = FACE_EMBEDDINGS_BACKEND,  detector_backend = FACE_DETECTION_BACKEND)\n",
    "        # For every face detected, store the image, face, embeddings, and dump the demography json\n",
    "        for idx, (f_data, e_data) in enumerate(zip(frame_data, embedding_data)):\n",
    "            file_name = f\"{session_id}_{frame_id}_{idx}\"\n",
    "            # Store the image\n",
    "            cv.imwrite(f\"data/frames/{file_name}.png\", frame)\n",
    "            # Extract the facial region and store/show the face\n",
    "            x,y,w,h = f_data[\"region\"][\"x\"], f_data[\"region\"][\"y\"], f_data[\"region\"][\"w\"], f_data[\"region\"][\"h\"]\n",
    "            # Make sure they represent the same face\n",
    "            assert(x == e_data[\"facial_area\"][\"x\"])\n",
    "            assert(y == e_data[\"facial_area\"][\"y\"])\n",
    "            assert(w == e_data[\"facial_area\"][\"w\"])\n",
    "            assert(h == e_data[\"facial_area\"][\"h\"])\n",
    "            x = max(int(x),0)\n",
    "            y = max(int(y),0)\n",
    "            w = max(int(w),0)\n",
    "            h = max(int(h),0)\n",
    "            face_region = frame[y:y+h, x:x+w,:]\n",
    "            cv.imwrite(f\"data/faces/{file_name}.png\", face_region)\n",
    "            cv.imshow(\"face\", face_region)\n",
    "            # Store the embeddings\n",
    "            np.save(f\"data/embeddings/{file_name}.npy\", e_data[\"embedding\"])\n",
    "            \n",
    "            # Dump the dict as a json\n",
    "            with open(f\"data/demography/{file_name}.json\", 'w') as f:\n",
    "                json.dump(f_data, f)\n",
    "            \n",
    "#         if len(frame_data) > 1:\n",
    "#             cv.imshow(\"face\", frame)\n",
    "#             cv2.setWindowProperty(\"face\", cv2.WND_PROP_TOPMOST, 1)\n",
    "        \n",
    "    except ValueError as ve:\n",
    "        # print(str(ve))\n",
    "        pass\n",
    "    except Exception as e:\n",
    "        print(str(e))\n",
    "        print(traceback.format_exc())\n",
    "        import ipdb; ipdb.set_trace()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2162828a-3065-46e3-9f90-f15220cccf50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_embeddings_k_means(n_clusters=15):\n",
    "    # List all embeddings\n",
    "    embed_files = os.listdir(\"data/embeddings/\")\n",
    "    # Load all embeddings and their associated names(without extensions)\n",
    "    embeddings = { f_name.split(\".\")[0] : np.load(f\"data/embeddings/{f_name}\") for f_name in embed_files}\n",
    "\n",
    "    # Cluster the embeddings using sklearn, get the cluster centroids\n",
    "    embed_vals = np.array([val for val in embeddings.values()])\n",
    "#     import ipdb; ipdb.set_trace()\n",
    "    k_means = KMeans(n_clusters=n_clusters, random_state=42, n_init=5)\n",
    "    k_means_results = k_means.fit(normalize(embed_vals))\n",
    "    # Get silhouette score\n",
    "    sil_score = silhouette_score(normalize(embed_vals), k_means.predict(normalize(embed_vals)))\n",
    "    print(f\"Silhouette score for K-Means : {sil_score:.4f}\")\n",
    "    # Assign the individual file prefix names to a centroid based on distance\n",
    "    cluster_assignments = {k:v for k,v in zip(embeddings.keys(), k_means_results.labels_)}\n",
    "    # Return file prefix - cluster number pairs and centroids\n",
    "    return (cluster_assignments, k_means_results.cluster_centers_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "017ebef9-7c1c-407c-8092-8f0c2b6ec69c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_embeddings_agglo(n_clusters=15):\n",
    "    # List all embeddings\n",
    "    embed_files = os.listdir(\"data/embeddings/\")\n",
    "    # Load all embeddings and their associated names(without extensions)\n",
    "    embeddings = {f_name.split(\".\")[0]: np.load(f\"data/embeddings/{f_name}\") for f_name in embed_files}\n",
    "\n",
    "    # Cluster the embeddings using sklearn agglo\n",
    "    embed_vals = np.array(list(embeddings.values()))\n",
    "    normalized_embed_vals = normalize(embed_vals)\n",
    "    agglo = AgglomerativeClustering(n_clusters=n_clusters)\n",
    "    agglo_results = agglo.fit(normalized_embed_vals)\n",
    "\n",
    "    # Get silhouette score\n",
    "    sil_score = silhouette_score(normalized_embed_vals, agglo_results.labels_)\n",
    "    print(f\"Silhouette score for agglomerative clustering : {sil_score:.4f}\")\n",
    "\n",
    "    # Assign the individual file prefix names to a centroid based on distance\n",
    "    cluster_assignments = dict(zip(embeddings.keys(), agglo_results.labels_))\n",
    "\n",
    "    # Compute centroids for each cluster\n",
    "    centroids = []\n",
    "    for cluster_id in range(n_clusters):\n",
    "        cluster_points = normalized_embed_vals[agglo_results.labels_ == cluster_id]\n",
    "        if len(cluster_points) > 0:\n",
    "            centroid = np.mean(cluster_points, axis=0)\n",
    "            centroids.append(centroid)\n",
    "        else:\n",
    "            centroids.append(np.zeros_like(embed_vals[0]))\n",
    "\n",
    "    # Return file prefix - cluster number pairs and centroids\n",
    "    return cluster_assignments, centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f0d4ea5c-a2f0-4c29-bcde-0e85be10c1c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensemble_demography_assignment(cluster_assignments, centroids):\n",
    "    # For each clustered face, get the demography data and use the one race and gender that appears the most and assign that\n",
    "    n_clusters = len(centroids)\n",
    "    \n",
    "    clustered_files = {}\n",
    "    demography = {}\n",
    "    for k,v in cluster_assignments.items():\n",
    "        if v not in clustered_files:\n",
    "            clustered_files[v] = []\n",
    "        clustered_files[v].append(k)\n",
    "    \n",
    "    for cluster, f_names in clustered_files.items():\n",
    "        race =[]\n",
    "        gender=[]\n",
    "        race_confidences = []\n",
    "        gender_confidences = []\n",
    "        for f_name in f_names:\n",
    "            with open(f\"data/demography/{f_name}.json\") as f:\n",
    "                demo_data = json.load(f)\n",
    "            race.append(demo_data.get(\"dominant_race\"))\n",
    "            gender.append(demo_data.get(\"dominant_gender\"))\n",
    "            race_confidences.append(demo_data.get(\"race\"))\n",
    "            gender_confidences.append(demo_data.get(\"gender\"))\n",
    "            demography[cluster] = {}\n",
    "            demography[cluster][\"race\"] = Counter(race).most_common(1)[0][0]\n",
    "            demography[cluster][\"gender\"] = Counter(gender).most_common(1)[0][0]\n",
    "            # For the assigned race and gender, calculate the median confidence for those classes\n",
    "            demography[cluster][\"race_confidence\"] = np.median([rc[demography[cluster][\"race\"]] for rc in race_confidences])\n",
    "            demography[cluster][\"gender_confidence\"] = np.median([gc[demography[cluster][\"gender\"]] for gc in gender_confidences])\n",
    "    # Return the cluster labels, and the race and gender with the median confidence\n",
    "    return demography"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c3a3a79a-099a-45b9-a671-5571de57aca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_representative_samples(cluster_assignments, centers):\n",
    "    \n",
    "    # Make a dict of cluster_no - files\n",
    "    clustered_files = {}\n",
    "    for k,v in cluster_assignments.items():\n",
    "        if v not in clustered_files:\n",
    "            clustered_files[v] = []\n",
    "        clustered_files[v].append(k)\n",
    "    \n",
    "    representative_samples = {}\n",
    "    for cluster, f_names in clustered_files.items():\n",
    "        distances = {}\n",
    "        center = normalize(centers[cluster].reshape(1,-1))\n",
    "        for f_name in f_names:\n",
    "            embedding = normalize(np.load(f\"data/embeddings/{f_name}.npy\").reshape(1,-1)) # Load the corresponding embedding\n",
    "            distances[f_name] = np.linalg.norm(embedding - center, ord=2) # Calculate and store the distance\n",
    "            distances = {k: v for k, v in sorted(distances.items(), key=lambda item: item[1])} # Sort by distances\n",
    "            representative_samples[cluster] = list(distances.keys())[:5]\n",
    "    return representative_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e3320821-be33-4b0b-b014-c36fe6d856ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Silhouette score for K-Means : 0.2474\n"
     ]
    }
   ],
   "source": [
    "# setup_experiment()\n",
    "# run_experiment('data/movie/sample.mp4')\n",
    "assignments, centers = cluster_embeddings_k_means(n_clusters=7)\n",
    "demography_data = ensemble_demography_assignment(assignments, centers)\n",
    "representative_samples = get_representative_samples(assignments, centers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4d59b0f3-ea3b-42ac-9f01-50e41e1dc85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for c,f_names in representative_samples.items():\n",
    "    for f_name in f_names:\n",
    "        frame = cv.imread(f\"data/faces/{f_name}.png\")\n",
    "        cv.imshow(f\"Person-{c}\", frame)\n",
    "        cv.waitKey(0)\n",
    "        cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "208ecb87-f997-4d32-9061-2891bd086ed6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Silhouette score for agglomerative clustering : 0.2566\n"
     ]
    }
   ],
   "source": [
    "assignments, centers = cluster_embeddings_agglo(n_clusters=7)\n",
    "demography_data = ensemble_demography_assignment(assignments, centers)\n",
    "representative_samples = get_representative_samples(assignments, centers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b8f1cf94-5150-41ce-b4a1-38897101581f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for c,f_names in representative_samples.items():\n",
    "    for f_name in f_names:\n",
    "        frame = cv.imread(f\"data/faces/{f_name}.png\")\n",
    "        cv.imshow(f\"Person-{c}\", frame)\n",
    "        cv.waitKey(0)\n",
    "        cv.destroyAllWindows()\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "825f65c2-1986-49e5-a47c-4664fec8c26e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # View all files with face #5\n",
    "# import time\n",
    "# relevant_files = [f\"data/faces/{k}.png\" for k,v in assignments.items() if v == 1]\n",
    "# for f in relevant_files:\n",
    "#     frame = cv.imread(f)\n",
    "#     cv.imshow(\"Person-5\", frame)\n",
    "#     # waits for user to press any key \n",
    "#     # (this is necessary to avoid Python kernel form crashing) \n",
    "#     cv.waitKey(0) \n",
    "\n",
    "#     # closing all open windows \n",
    "#     cv.destroyAllWindows() \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7558015-73ec-47db-b83e-d90b6ae1bea9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dissertation-env",
   "language": "python",
   "name": "dissertation-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
