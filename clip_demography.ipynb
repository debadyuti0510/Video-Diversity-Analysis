{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "8e50f81d-c3ad-4ca0-a23b-57d7ac20bb20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from PIL import Image\n",
    "from transformers import CLIPProcessor, CLIPModel\n",
    "from tqdm import tqdm\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "96f4907b-6227-482e-940c-671c98d854a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_experiment():\n",
    "    # Remove clip demography folder\n",
    "    if os.path.exists(\"data/clip_demography\"):\n",
    "        shutil.rmtree(\"data/clip_demography\")\n",
    "    os.mkdir(\"data/clip_demography\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "1c20b11e-254e-44dc-b431-d1a14ddb8898",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_demography_data_with_clip():\n",
    "    # Class refs\n",
    "    class_gender_refs = [\n",
    "        \"man\",\n",
    "        \"woman\"\n",
    "    ]\n",
    "    class_race_refs=[\"East Asian\",\n",
    "        \"Indian\",\n",
    "        \"Black\",\n",
    "        \"White\",\n",
    "        \"Middle Eastern\",\n",
    "        \"Latino Hispanic\",\n",
    "        \"Southeast Asian\"\n",
    "    ]\n",
    "    class_emotion_refs = [\n",
    "        \"angry\", \n",
    "        \"fear\", \n",
    "        \"neutral\", \n",
    "        \"sad\", \n",
    "        \"disgust\", \n",
    "        \"happy\", \n",
    "        \"surprise\"\n",
    "    ]\n",
    "        \n",
    "        \n",
    "    # Load model and pre-processor\n",
    "    model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "    processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "    # Get face file names\n",
    "    face_files = os.listdir(\"data/faces\")\n",
    "    f_names = [f\"data/faces/{file}\" for file in face_files]\n",
    "    \n",
    "    # Create batches of faces (8 at a time), generate their file\n",
    "    batch_size = 8\n",
    "    for idx in tqdm(range(0,len(f_names), batch_size)):\n",
    "        rel_f_names = f_names[idx:idx+batch_size]\n",
    "        demo_data = []\n",
    "        rel_images = [Image.open(rel_f_name) for rel_f_name in rel_f_names] # Load relevant images in batch\n",
    "        # Get gender and confidences\n",
    "        inputs = processor(text=[\"the face of a man\", \"the face of a woman\"], images=rel_images, return_tensors=\"pt\", padding=True)\n",
    "        outputs = model(**inputs)\n",
    "        logits_per_image = outputs.logits_per_image # this is the image-text similarity score\n",
    "        gender_probs = logits_per_image.softmax(dim=1) # we can take the softmax to get the label probabilities\n",
    "        # Get race and confidences\n",
    "        inputs = processor(text=[\"East Asian\", \"Indian\", \"Black\", \"White\", \"Middle Eastern\", \"Latino Hispanic\", \"Southeast Asian\"], images=rel_images, return_tensors=\"pt\", padding=True)\n",
    "        outputs = model(**inputs)\n",
    "        logits_per_image = outputs.logits_per_image # this is the image-text similarity score\n",
    "        race_probs = logits_per_image.softmax(dim=1) # we can take the softmax to get the label probabilities\n",
    "        # Get emotion and confidences\n",
    "        inputs = processor(text=[\"angry emotion\", \"emotion of fear\", \"neutral emotion\", \"sad emotion\", \"emotion of disgust\", \"happy emotion\", \"emotion of surprise\"], images=rel_images, return_tensors=\"pt\", padding=True)\n",
    "        outputs = model(**inputs)\n",
    "        logits_per_image = outputs.logits_per_image # this is the image-text similarity score\n",
    "        emotion_probs = logits_per_image.softmax(dim=1) # we can take the softmax to get the label probabilities\n",
    "        for jdx in range(len(gender_probs)):\n",
    "            g_probs, r_probs, e_probs = gender_probs[jdx], race_probs[jdx], emotion_probs[jdx] \n",
    "            tmp_demo={}\n",
    "            \n",
    "            tmp_demo[\"dominant_emotion\"] = class_emotion_refs[int(torch.argmax(e_probs))]\n",
    "            tmp_demo[\"emotion\"] = {\n",
    "                k: float(v) for k,v in zip(class_emotion_refs, e_probs)\n",
    "            }\n",
    "            \n",
    "            tmp_demo[\"dominant_race\"] = class_race_refs[int(torch.argmax(r_probs))]\n",
    "            tmp_demo[\"race\"] = {\n",
    "                k: float(v) for k,v in zip(class_race_refs, r_probs)\n",
    "            }\n",
    "            \n",
    "            tmp_demo[\"dominant_gender\"] = class_gender_refs[int(torch.argmax(g_probs))]\n",
    "            tmp_demo[\"gender\"] = {\n",
    "                k: float(v) for k,v in zip(class_gender_refs, g_probs)\n",
    "            }\n",
    "            json_name = rel_f_names[jdx].split(\"/\")[-1].split(\".\")[0]\n",
    "            demo_data.append((json_name, tmp_demo))\n",
    "    import pdb; pdb.set_trace()\n",
    "    print(\"Saving:\")\n",
    "    for f_name, demography in tqdm(demo_data):\n",
    "        with open(f\"data/clip_demography/{f_name}.json\", \"w\") as f:\n",
    "            json.dump(demography, f)\n",
    "        \n",
    "            \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "860ee246-a369-4945-b79d-ac735d130997",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 141/141 [08:50<00:00,  3.76s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[1;32mc:\\users\\debadyuti\\appdata\\local\\temp\\ipykernel_35272\\2255756544.py\u001b[0m(75)\u001b[0;36mgenerate_demography_data_with_clip\u001b[1;34m()\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  c\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 75.27it/s]\n"
     ]
    }
   ],
   "source": [
    "setup_experiment()\n",
    "generate_demography_data_with_clip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "5b236eb3-e317-44ed-a383-2b55c5520a87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('f97f_9870_0',\n",
       "  {'dominant_emotion': 'disgust',\n",
       "   'emotion': {'angry': 0.18374894559383392,\n",
       "    'fear': 0.0740252286195755,\n",
       "    'neutral': 0.10968844592571259,\n",
       "    'sad': 0.0838051363825798,\n",
       "    'disgust': 0.2827147841453552,\n",
       "    'happy': 0.05140778422355652,\n",
       "    'surprise': 0.21460969746112823},\n",
       "   'dominant_race': 'Indian',\n",
       "   'race': {'East Asian': 0.06731825321912766,\n",
       "    'Indian': 0.47527313232421875,\n",
       "    'Black': 0.030623245984315872,\n",
       "    'White': 0.07833714038133621,\n",
       "    'Middle Eastern': 0.26388126611709595,\n",
       "    'Latino Hispanic': 0.06679756194353104,\n",
       "    'Southeast Asian': 0.017769306898117065},\n",
       "   'dominant_gender': 'man',\n",
       "   'gender': {'man': 0.927132248878479, 'woman': 0.07286779582500458}}),\n",
       " ('f97f_9885_0',\n",
       "  {'dominant_emotion': 'disgust',\n",
       "   'emotion': {'angry': 0.1445969194173813,\n",
       "    'fear': 0.05276205390691757,\n",
       "    'neutral': 0.05592034384608269,\n",
       "    'sad': 0.08061965554952621,\n",
       "    'disgust': 0.45087555050849915,\n",
       "    'happy': 0.020155970007181168,\n",
       "    'surprise': 0.19506953656673431},\n",
       "   'dominant_race': 'Middle Eastern',\n",
       "   'race': {'East Asian': 0.031065989285707474,\n",
       "    'Indian': 0.2963835597038269,\n",
       "    'Black': 0.0540328286588192,\n",
       "    'White': 0.12215729057788849,\n",
       "    'Middle Eastern': 0.3828771114349365,\n",
       "    'Latino Hispanic': 0.10426966845989227,\n",
       "    'Southeast Asian': 0.009213457815349102},\n",
       "   'dominant_gender': 'woman',\n",
       "   'gender': {'man': 0.02929438278079033, 'woman': 0.9707056283950806}}),\n",
       " ('f97f_9900_0',\n",
       "  {'dominant_emotion': 'disgust',\n",
       "   'emotion': {'angry': 0.1276211440563202,\n",
       "    'fear': 0.01907738856971264,\n",
       "    'neutral': 0.07451149821281433,\n",
       "    'sad': 0.09173360466957092,\n",
       "    'disgust': 0.5764783024787903,\n",
       "    'happy': 0.032914210110902786,\n",
       "    'surprise': 0.07766390591859818},\n",
       "   'dominant_race': 'Middle Eastern',\n",
       "   'race': {'East Asian': 0.08426894247531891,\n",
       "    'Indian': 0.2787246108055115,\n",
       "    'Black': 0.12213746458292007,\n",
       "    'White': 0.14935623109340668,\n",
       "    'Middle Eastern': 0.2931540906429291,\n",
       "    'Latino Hispanic': 0.05810923129320145,\n",
       "    'Southeast Asian': 0.014249462634325027},\n",
       "   'dominant_gender': 'woman',\n",
       "   'gender': {'man': 0.02567286603152752, 'woman': 0.9743271470069885}}),\n",
       " ('f97f_9915_0',\n",
       "  {'dominant_emotion': 'disgust',\n",
       "   'emotion': {'angry': 0.1731174886226654,\n",
       "    'fear': 0.012989755719900131,\n",
       "    'neutral': 0.04224952310323715,\n",
       "    'sad': 0.10860062390565872,\n",
       "    'disgust': 0.5598713755607605,\n",
       "    'happy': 0.031467560678720474,\n",
       "    'surprise': 0.07170359045267105},\n",
       "   'dominant_race': 'Indian',\n",
       "   'race': {'East Asian': 0.07772251963615417,\n",
       "    'Indian': 0.4554542899131775,\n",
       "    'Black': 0.03502313047647476,\n",
       "    'White': 0.0392703078687191,\n",
       "    'Middle Eastern': 0.3371118903160095,\n",
       "    'Latino Hispanic': 0.04465562105178833,\n",
       "    'Southeast Asian': 0.010762270539999008},\n",
       "   'dominant_gender': 'woman',\n",
       "   'gender': {'man': 0.025088971480727196, 'woman': 0.9749109745025635}}),\n",
       " ('f97f_9930_0',\n",
       "  {'dominant_emotion': 'disgust',\n",
       "   'emotion': {'angry': 0.09916063398122787,\n",
       "    'fear': 0.006346881855279207,\n",
       "    'neutral': 0.022099914029240608,\n",
       "    'sad': 0.09877572953701019,\n",
       "    'disgust': 0.715260922908783,\n",
       "    'happy': 0.017201421782374382,\n",
       "    'surprise': 0.04115457460284233},\n",
       "   'dominant_race': 'Indian',\n",
       "   'race': {'East Asian': 0.05656510964035988,\n",
       "    'Indian': 0.4590204060077667,\n",
       "    'Black': 0.02308706007897854,\n",
       "    'White': 0.01678820140659809,\n",
       "    'Middle Eastern': 0.42496925592422485,\n",
       "    'Latino Hispanic': 0.011792412959039211,\n",
       "    'Southeast Asian': 0.007777498569339514},\n",
       "   'dominant_gender': 'woman',\n",
       "   'gender': {'man': 0.017675168812274933, 'woman': 0.9823248386383057}})]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7848c7bf-6d2a-4f3e-aca7-7ee417a892dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb73fbc3-2909-48ba-b4ad-0b8ac93f2e81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "a9b686a3-74c8-41f7-abc7-7cb386d1e47e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "!conda install pytorch torchvision torchaudio pytorch-cuda=12.1 -c pytorch -c nvidia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "ce0b390b-e91b-4aa4-8ada-ec2fc134137b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "875bc6dd-8c15-4440-98a6-be249b5500db",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e696d51-cd9f-4bbc-b2e2-c008fe84b3f6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf1824e-3286-4cee-b0a7-25a2e81b3f9b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "048ab47a-74d1-43ed-b997-1380b5ed7280",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed368da-d900-44cd-a74f-08a46a163d8e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dissertation-env",
   "language": "python",
   "name": "dissertation-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
