{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "import numpy as np\n",
    "import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load validation data and test on this\n",
    "valid_ds = datasets.load_dataset('HuggingFaceM4/FairFace', '1.25', split=\"validation\", verification_mode=\"no_checks\")\n",
    "valid_ds = valid_ds.shuffle(seed=42)\n",
    "# valid_ds = valid_ds.shuffle(seed=42)\n",
    "y_true = np.array(valid_ds[\"age\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(y_preds, y_true, header=''):\n",
    "    precision, recall, f_score_weighted, _ = precision_recall_fscore_support(y_true, y_preds, average='weighted')\n",
    "    _, _, f_score_macro, _ = precision_recall_fscore_support(y_true, y_preds, average='macro')\n",
    "    _, _, f_score_micro, _ = precision_recall_fscore_support(y_true, y_preds, average='micro')\n",
    "    class_rep = classification_report( y_true, y_preds, output_dict=True)\n",
    "    print(f\"{header} \\n\" + \"=\"*40)\n",
    "    print(f\"Accuracy: {class_rep['accuracy']:.4f} Precision: {precision:.4f}, Recall: {recall:.4f}, F-Score(Weighted): {f_score_weighted:.4f}, F-Score(Micro): {f_score_micro:.4f}, F-Score(Macro): {f_score_macro:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_over_under_50(y_preds, y_true):\n",
    "    # Up to 50 is 0, over 50 is 1 \n",
    "    y_ou_preds = np.array(y_preds) >= 6 # Classes 0 to 5 are up to 50, 6 and above are over 50 \n",
    "    y_ou_true = np.array(y_true) >= 6 # Classes 0 to 5 are up to 50, 6 and above are over 50 \n",
    "    print(classification_report( y_ou_true, y_ou_preds, labels=[0,1],target_names=[\"Up to 50\", \"Over 50\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_regression_to_class(y_preds_reg):\n",
    "    # Define the boundaries\n",
    "    bins = [-np.inf, 2, 9, 19, 29, 39, 49, 59, 69, np.inf]\n",
    "    # Map each prediction to its bin\n",
    "    y_preds = np.digitize(y_preds_reg, bins) - 1  # np.digitize returns indices starting from 1\n",
    "    return y_preds\n",
    "# y_preds_reg = np.array([1, 4, 15, 22, 35, 46, 55, 62, 77])\n",
    "# y_preds = map_regression_to_class(y_preds_reg)\n",
    "\n",
    "# print(y_preds)\n",
    "# Output: [0 1 2 3 4 5 6 7 8]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation set metrics - Age (CLIP ZS)  \n",
      "========================================\n",
      "Accuracy: 0.3984 Precision: 0.4782, Recall: 0.3984, F-Score(Weighted): 0.4110, F-Score(Micro): 0.3984, F-Score(Macro): 0.3714\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Up to 50       0.98      0.88      0.93      9719\n",
      "     Over 50       0.47      0.88      0.61      1235\n",
      "\n",
      "    accuracy                           0.88     10954\n",
      "   macro avg       0.73      0.88      0.77     10954\n",
      "weighted avg       0.93      0.88      0.89     10954\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# CLIP ZS evaluation\n",
    "y_preds = np.load(\"clip_zs_age_preds_val_42.npy\")\n",
    "evaluate(y_preds, y_true, header='Validation set metrics - Age (CLIP ZS) ')\n",
    "map_over_under_50(y_preds, y_true)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation set metrics - Age (CLIP + LR)  \n",
      "========================================\n",
      "Accuracy: 0.6013 Precision: 0.5953, Recall: 0.6013, F-Score(Weighted): 0.5958, F-Score(Micro): 0.6013, F-Score(Macro): 0.5667\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Up to 50       0.96      0.97      0.97      9719\n",
      "     Over 50       0.75      0.70      0.73      1235\n",
      "\n",
      "    accuracy                           0.94     10954\n",
      "   macro avg       0.86      0.84      0.85     10954\n",
      "weighted avg       0.94      0.94      0.94     10954\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# CLIP LR evaluation\n",
    "y_preds = np.load(\"clip_lr_age_preds_val_42.npy\")\n",
    "evaluate(y_preds, y_true, header='Validation set metrics - Age (CLIP + LR) ')\n",
    "map_over_under_50(y_preds, y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation set metrics - Age (Deepface)  \n",
      "========================================\n",
      "Accuracy: 0.2663 Precision: 0.2495, Recall: 0.2663, F-Score(Weighted): 0.2191, F-Score(Micro): 0.2663, F-Score(Macro): 0.1545\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Up to 50       0.92      0.98      0.95      9719\n",
      "     Over 50       0.70      0.29      0.41      1235\n",
      "\n",
      "    accuracy                           0.91     10954\n",
      "   macro avg       0.81      0.64      0.68     10954\n",
      "weighted avg       0.89      0.91      0.89     10954\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       199\n",
      "           1       0.00      0.00      0.00      1356\n",
      "           2       0.20      0.01      0.01      1181\n",
      "           3       0.37      0.22      0.28      3300\n",
      "           4       0.24      0.59      0.34      2330\n",
      "           5       0.24      0.45      0.31      1353\n",
      "           6       0.37      0.17      0.24       796\n",
      "           7       0.37      0.15      0.21       321\n",
      "           8       0.00      0.00      0.00       118\n",
      "\n",
      "    accuracy                           0.27     10954\n",
      "   macro avg       0.20      0.18      0.15     10954\n",
      "weighted avg       0.25      0.27      0.22     10954\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Debadyuti\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\Debadyuti\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\Debadyuti\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\Debadyuti\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\Debadyuti\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\Debadyuti\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\Debadyuti\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\Debadyuti\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Deepface \n",
    "classes = [\"0-2\", \"3-9\", \"10-19\", \"20-29\", \"30-39\", \"40-49\", \"50-59\", \"60-69\", \"more than 70\"]\n",
    "y_preds_reg = np.load(\"deepace_age_preds_val_42.npy\")\n",
    "y_preds = map_regression_to_class(y_preds_reg)\n",
    "evaluate(y_preds, y_true, header='Validation set metrics - Age (Deepface) ')\n",
    "map_over_under_50(y_preds, y_true)\n",
    "print(classification_report(y_true, y_preds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validate GENDER for FAIRFACE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = np.array(valid_ds[\"gender\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation set metrics - Age (ZS)  \n",
      "========================================\n",
      "Accuracy: 0.9506 Precision: 0.9512, Recall: 0.9506, F-Score(Weighted): 0.9506, F-Score(Micro): 0.9506, F-Score(Macro): 0.9505\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Male       0.97      0.94      0.95      5792\n",
      "      Female       0.93      0.96      0.95      5162\n",
      "\n",
      "    accuracy                           0.95     10954\n",
      "   macro avg       0.95      0.95      0.95     10954\n",
      "weighted avg       0.95      0.95      0.95     10954\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_preds = np.load(\"clip_zs_gender_preds_val_42.npy\")\n",
    "evaluate(y_preds, y_true, header='Validation set metrics - Gender (ZS) ')\n",
    "print(classification_report(y_true, y_preds, labels=[0,1], target_names=[\"Male\", \"Female\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation set metrics - Age (CLIP + LR)  \n",
      "========================================\n",
      "Accuracy: 0.9616 Precision: 0.9616, Recall: 0.9616, F-Score(Weighted): 0.9616, F-Score(Micro): 0.9616, F-Score(Macro): 0.9615\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Male       0.97      0.96      0.96      5792\n",
      "      Female       0.96      0.96      0.96      5162\n",
      "\n",
      "    accuracy                           0.96     10954\n",
      "   macro avg       0.96      0.96      0.96     10954\n",
      "weighted avg       0.96      0.96      0.96     10954\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_preds = np.load(\"clip_lr_gender_preds_val_42.npy\")\n",
    "evaluate(y_preds, y_true, header='Validation set metrics - Gender (CLIP + LR) ')\n",
    "print(classification_report(y_true, y_preds, labels=[0,1], target_names=[\"Male\", \"Female\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation set metrics - Gender (DeepFace)  \n",
      "========================================\n",
      "Accuracy: 0.7793 Precision: 0.7865, Recall: 0.7793, F-Score(Weighted): 0.7763, F-Score(Micro): 0.7793, F-Score(Macro): 0.7743\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Male       0.75      0.88      0.81      5792\n",
      "      Female       0.83      0.67      0.74      5162\n",
      "\n",
      "    accuracy                           0.78     10954\n",
      "   macro avg       0.79      0.77      0.77     10954\n",
      "weighted avg       0.79      0.78      0.78     10954\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_preds = np.load(\"deepace_gender_preds_val_42.npy\")\n",
    "evaluate(y_preds, y_true, header='Validation set metrics - Gender (DeepFace) ')\n",
    "print(classification_report(y_true, y_preds, labels=[0,1], target_names=[\"Male\", \"Female\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 1.0, 1: 0.5, 2: 0.3333333333333333}\n"
     ]
    }
   ],
   "source": [
    "def accuracy_per_class(y_true, y_pred):\n",
    "    classes = np.unique(y_true)\n",
    "    accuracies = {}\n",
    "    \n",
    "    for cls in classes:\n",
    "        idx = np.where(y_true == cls)[0]  # indices where the true label is class cls\n",
    "        correct = np.sum(y_pred[idx] == y_true[idx])\n",
    "        accuracies[cls] = correct / len(idx) if len(idx) > 0 else 0.0\n",
    "        \n",
    "    return accuracies\n",
    "\n",
    "# Example usage:\n",
    "y_true = np.array([0, 1, 2, 1, 0, 2, 2])\n",
    "y_pred = np.array([0, 2, 1, 1, 0, 2, 1])\n",
    "\n",
    "print(accuracy_per_class(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dissertation-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
